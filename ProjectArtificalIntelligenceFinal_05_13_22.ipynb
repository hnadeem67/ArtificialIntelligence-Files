{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "5o14wl2x-cf7"
   },
   "outputs": [],
   "source": [
    "# Version 1.01\n",
    "# Authors: 1) Hamza Nadeem\n",
    "#          2) Monica Restrepo\n",
    "#          3) Nency Borad\n",
    "#          4) Ajinkya Mukherjee\n",
    "# Date      Name  Version Description\n",
    "# 5/6/2022  SCL   1.01    Refactor code for Hypothesis (part II), and remove all\n",
    "#                         EDA code.\n",
    "#                 1.01    Perform Feature Selection and create utility matrix\n",
    "#                         labelled data, for supervised machine learning\n",
    "#\n",
    "# -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "A1Nz23PhwyuA"
   },
   "outputs": [],
   "source": [
    "# Features: 1) PopSize \n",
    "#           2) Time\n",
    "#           3) Date\n",
    "#           4) Num of complaints\n",
    "#           5) Type of Crime [Felony, Misdorminor, Violation]\n",
    "#           -) Class = [ Low Crime, Medium Crime, High Crime ]\n",
    "#               10 = Low\n",
    "#              200 = Medium\n",
    "#             9000 = High\n",
    "\n",
    "# Hypo: FIgure out which zip codes will increase/dec in crime rate? \n",
    "#and we need to categorize the dataset into LOW MID HIGH  \n",
    "# Algorithms: 1) SVM\n",
    "#             2) Bayes (NB)\n",
    "#             3) Random Forest\n",
    "#             4) Logistic Regression (0 or 1)\n",
    "# -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "G_okfUMr91gm"
   },
   "outputs": [],
   "source": [
    "# Questions to ask Professor\n",
    "# Q1: We did all this, how do add them to our Feature list\n",
    "# Q2: How do we Classify what is high,low,medium ( How do we get the score) = Range of the score\n",
    "# Q3: How do we get Population by Zipcode from total population of Burrow\n",
    "# Q4: Can we use the Number of Crimes in Each Zipcode as our Feature for number of complaints / per area\n",
    "# Q5: How do we add Labels to our dataset inorder to Train them - adding Labels to the Testing set\n",
    "# Q6: How does the iris dataset have so many features & Classes, how do we optimize our features accordingly \n",
    "#     and why do we require so many featueres and Classes?\n",
    "# Q7: Are we implementing the Alogirthms correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UzdfRCrN3i7F",
    "outputId": "3e9eecb3-6ab7-4969-f860-57c75e395ead"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.flush_and_unmount()\n",
    "#drive.mount('/content/gdrive');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ahKear6-Iz9I",
    "outputId": "b5746324-5fcd-4619-9765-802a85a8a957"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pgeocode in c:\\programdata\\anaconda3\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from pgeocode) (2.26.0)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from pgeocode) (1.3.4)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from pgeocode) (1.20.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->pgeocode) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->pgeocode) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->pgeocode) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pgeocode) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pgeocode) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pgeocode) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pgeocode) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "# !pip install modin[ray]\n",
    "!pip install pgeocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn-intelex in c:\\programdata\\anaconda3\\lib\\site-packages (2021.20210714.120553)\n",
      "Requirement already satisfied: daal4py>=2021.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn-intelex) (2021.3.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn-intelex) (1.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.Collecting daal==2021.2.3\n",
      "  Using cached daal-2021.2.3-py2.py3-none-win_amd64.whl (63.9 MB)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from daal4py>=2021.2->scikit-learn-intelex) (1.20.3)\n",
      "Collecting tbb==2021.*\n",
      "  Using cached tbb-2021.6.0-py3-none-win_amd64.whl (278 kB)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.7.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22->scikit-learn-intelex) (2.2.0)\n",
      "Installing collected packages: tbb, daal\n",
      "  Attempting uninstall: tbb\n",
      "    Found existing installation: TBB 0.2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn-intelex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn \n",
    "\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w2Kq7rFeoomm",
    "outputId": "e31fa2c8-80ab-4d61-ef43-3171c36d85e2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(r'C:\\Users\\hnade\\Downloads\\AI\\final_project_csvs\\NYPD_Complaint_Data_Historic.csv', low_memory=False)\n",
    "df2 = pd.read_csv(r'C:\\Users\\hnade\\Downloads\\AI\\final_project_csvs\\Crime_Column_Description.csv', low_memory=False)\n",
    "df3 = pd.read_csv(r'C:\\Users\\hnade\\Downloads\\AI\\final_project_csvs\\Population_by_Borough_NYC.csv', low_memory=False)\n",
    "#df4 = pd.read_csv('/content/gdrive/MyDrive/AI/final_project_csvs/ziptoborough.csv')\n",
    "# newData = pd.read_csv('US.csv')\n",
    "# zip_codes = pd.read_csv('/content/gdrive/MyDrive/AI/final_project_csvs/us.csv')\n",
    "\n",
    "# zip_codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "NQ3bVYp1JJSE",
    "outputId": "9031989e-b1a8-44e7-a6a0-40c8609e77a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-73.916661</td>\n",
       "      <td>40.828848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-73.784557</td>\n",
       "      <td>40.697338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-73.945052</td>\n",
       "      <td>40.802607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-73.726339</td>\n",
       "      <td>40.654549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-73.987891</td>\n",
       "      <td>40.738002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>-73.920767</td>\n",
       "      <td>40.806932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>-73.895227</td>\n",
       "      <td>40.660901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>-74.004681</td>\n",
       "      <td>40.723909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>-73.872939</td>\n",
       "      <td>40.877554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>-73.940855</td>\n",
       "      <td>40.814113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Longitude   Latitude\n",
       "0       -73.916661  40.828848\n",
       "1       -73.784557  40.697338\n",
       "2       -73.945052  40.802607\n",
       "3       -73.726339  40.654549\n",
       "4       -73.987891  40.738002\n",
       "...            ...        ...\n",
       "1048570 -73.920767  40.806932\n",
       "1048571 -73.895227  40.660901\n",
       "1048572 -74.004681  40.723909\n",
       "1048573 -73.872939  40.877554\n",
       "1048574 -73.940855  40.814113\n",
       "\n",
       "[1048575 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df5 = pd.DataFrame(df1[['Longitude','Latitude']])\n",
    "# df1['Latitude']\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "Famm8wj-ShXv"
   },
   "outputs": [],
   "source": [
    "# 54.143 - Lat\n",
    "# -165.7854 - Long\n",
    "# zc = zip_codes.head(10)\n",
    "# zc\n",
    "\n",
    "\n",
    "#helper\n",
    "\n",
    "# def findZip(lat, long):\n",
    "  # print('lat', \"%.4f\" % lat)\n",
    "\n",
    "  # lat = \"%.4f\" % lat\n",
    "  # long = \"%.4f\" % long\n",
    "  # print('lat', lat)\n",
    "  # print('long', long)\n",
    "  # t = np.where((zip_codes['Latitude'] == lat) & (zip_codes['Longitude'] == long), zip_codes['ZIP'], 99999)\n",
    "  # print('here====>', t)\n",
    "  # if zip_codes['Latitude'] == lat:\n",
    "  #   if zip_codes['Longitude'] == long:\n",
    "  #     print('We got it!!', zip_codes['Zip'])\n",
    "\n",
    "# s= df5.head(20)\n",
    "# df5['Longitude'] = df5['Longitude'].astype(float)\n",
    "# df5['Latitude'] = df5['Latitude'].astype(float)\n",
    "# df5['Longitude'] = \"%.6f\" % df5['Longitude']\n",
    "# df5['Latitude'] = \"%.6f\" % df5['Latitude']\n",
    "\n",
    "# df5 = np.where(df1['Latitude'] == zc['Latitude'] and df1['Longitude'] == zc['Longitude'],zc['zip'],99999)\n",
    "# # t\n",
    "# for i, value in s.iterrows():\n",
    "#   # print('idx', i)\n",
    "#   # print('value ====> ', value)\n",
    "#   findZip(value['Latitude'], value['Longitude'])\n",
    "    # print('lat only :::::>', value['Latitude'])\n",
    "\n",
    "\n",
    "# df5['Zipcode'] = np.where(df1['Latitude'] == zip_codes['Latitude'] and df1['Longitude'] == zip_codes['Longitude'],zip_codes['zip'],99999)\n",
    "\n",
    "# newData['LONG']\n",
    "# zipcode_Dict = newData.set_index('ZIP').T.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "lldL9TijaQj9"
   },
   "outputs": [],
   "source": [
    "# zipcode_Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "tKryC3bm41mp"
   },
   "outputs": [],
   "source": [
    "def makeCategories(df):\n",
    "  category = [health,residence,worship,pub,retail,Tranportation,Food_Beverage,finance,other]\n",
    "  residence_count = 0\n",
    "  health_count = 0\n",
    "  worship_count = 0\n",
    "  pub_count = 0\n",
    "  retial_count = 0\n",
    "  tranport_count = 0\n",
    "  foodbev_count = 0\n",
    "  finance_count = 0\n",
    "  other_count = 0\n",
    "  df['Food & beverage'] = 0\n",
    "\n",
    "  for a in df['PREM_TYP_DESC']:\n",
    "    if a in residence:      \n",
    "      residence_count += 1\n",
    "      \n",
    "    if a in other:\n",
    "      other_count += 1\n",
    "\n",
    "    if a in finance:\n",
    "      finance_count += 1\n",
    "\n",
    "    if a in Food_Beverage:\n",
    "      foodbev_count += 1\n",
    "      df['Food and beverage'] = 1\n",
    "      pass\n",
    "\n",
    "    if a in Tranportation:\n",
    "      tranport_count += 1\n",
    "\n",
    "    if a in retail:\n",
    "      retial_count += 1\n",
    "\n",
    "    if a in worship:\n",
    "      worship_count += 1\n",
    "        \n",
    "    if a in health:\n",
    "      health_count += 1\n",
    "      \n",
    "  print('residence',residence_count)\n",
    "  print('other',other_count)\n",
    "  print('finance',finance_count)\n",
    "  print('food',foodbev_count)        \n",
    "  print('Transport',tranport_count)\n",
    "  print('Retail',retial_count)\n",
    "  print('Worship',worship_count)\n",
    "  print('Health',health_count)\n",
    "\n",
    "  return residence_count, other_count, finance_count, foodbev_count, tranport_count, retial_count, worship_count, health_count, pub_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "meHu0-yihWnZ"
   },
   "outputs": [],
   "source": [
    "#df1 = df1.sample(500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "CBDQoLQBiIfg"
   },
   "outputs": [],
   "source": [
    "health = ['DRUG STORE','DOCTOR/DENTIST OFFICE','HOSPITAL']\n",
    "residence = ['RESIDENCE-HOUSE','RESIDENCE - APT. HOUSE','RESIDENCE - PUBLIC HOUSING']\n",
    "worship = ['CHURCH','SYNAGOGUE','OTHER HOUSE OF WORSHIP','MOSQUE']\n",
    "pub = ['STREET','PUBLIC BUILDING','PARK/PLAYGROUND','PARKING LOT/GARAGE (PUBLIC)','PRIVATE/PAROCHIAL SCHOOL','BOOK/CARD','MARINA/PIER',\n",
    "       'PUBLIC SCHOOL','CEMETERY']\n",
    "retail = ['DRY CLEANER/LAUNDRY','GAS STATION','CHAIN STORE','BEAUTY & NAIL SALON',\n",
    "          'COMMERCIAL BUILDING','HOTEL/MOTEL','SMALL MERCHANT','PARKING LOT/GARAGE (PRIVATE)',\n",
    "          'DEPARTMENT STORE','GYM/FITNESS FACILITY','VARIETY STORE','CLOTHING/BOUTIQUE','TELECOMM. STORE',\n",
    "          'JEWELRY','CANDY STORE','STORAGE FACILITY','VIDEO STORE']\n",
    "Tranportation = ['TUNNEL','TRANSIT - NYC SUBWAY','BUS (NYC TRANSIT)','FERRY/FERRY TERMINAL','BUS STOP','TAXI (LIVERY LICENSED)',\n",
    "                 'BRIDGE','AIRPORT TERMINAL','HIGHWAY/PARKWAY','BUS (OTHER)',\n",
    "                 'TRANSIT FACILITY (OTHER)','BUS TERMINAL','TAXI (YELLOW LICENSED)','TAXI/LIVERY (UNLICENSED)','TRAMWAY']\n",
    "Food_Beverage= ['BAR/NIGHT CLUB' , 'FAST FOOD' , 'RESTAURANT/DINER' , 'GROCERY/BODEGA' , 'FOOD SUPERMARKET' , 'SOCIAL CLUB/POLICY' , 'LIQUOR STORE']\n",
    "finance = ['CHECK CASHING BUSINESS','BANK','ATM','LOAN COMPANY']\n",
    "other = ['OTHER','STORE UNCLASSIFIED','CONSTRUCTION SITE','FACTORY/WAREHOUSE','OPEN AREAS (OPEN LOTS)','ABANDONED BUILDING','SHOE','PHOTO/COPY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "HNxU7_SU-su0",
    "outputId": "c6a49059-5a35-42bf-f26e-37144960c55a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CMPLNT_NUM</th>\n",
       "      <th>CMPLNT_FR_DT</th>\n",
       "      <th>CMPLNT_FR_TM</th>\n",
       "      <th>CMPLNT_TO_DT</th>\n",
       "      <th>CMPLNT_TO_TM</th>\n",
       "      <th>RPT_DT</th>\n",
       "      <th>KY_CD</th>\n",
       "      <th>OFNS_DESC</th>\n",
       "      <th>PD_CD</th>\n",
       "      <th>PD_DESC</th>\n",
       "      <th>...</th>\n",
       "      <th>ADDR_PCT_CD</th>\n",
       "      <th>LOC_OF_OCCUR_DESC</th>\n",
       "      <th>PREM_TYP_DESC</th>\n",
       "      <th>PARKS_NM</th>\n",
       "      <th>HADEVELOPT</th>\n",
       "      <th>X_COORD_CD</th>\n",
       "      <th>Y_COORD_CD</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Lat_Lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101109527</td>\n",
       "      <td>12/31/2015</td>\n",
       "      <td>23:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/31/2015</td>\n",
       "      <td>113</td>\n",
       "      <td>FORGERY</td>\n",
       "      <td>729.0</td>\n",
       "      <td>FORGERY,ETC.,UNCLASSIFIED-FELO</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>INSIDE</td>\n",
       "      <td>BAR/NIGHT CLUB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1007314.0</td>\n",
       "      <td>241257.0</td>\n",
       "      <td>40.828848</td>\n",
       "      <td>-73.916661</td>\n",
       "      <td>(40.828848333, -73.916661142)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>153401121</td>\n",
       "      <td>12/31/2015</td>\n",
       "      <td>23:36:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/31/2015</td>\n",
       "      <td>101</td>\n",
       "      <td>MURDER &amp; NON-NEGL. MANSLAUGHTER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>OUTSIDE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1043991.0</td>\n",
       "      <td>193406.0</td>\n",
       "      <td>40.697338</td>\n",
       "      <td>-73.784557</td>\n",
       "      <td>(40.697338138, -73.784556739)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>569369778</td>\n",
       "      <td>12/31/2015</td>\n",
       "      <td>23:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/31/2015</td>\n",
       "      <td>117</td>\n",
       "      <td>DANGEROUS DRUGS</td>\n",
       "      <td>503.0</td>\n",
       "      <td>CONTROLLED SUBSTANCE,INTENT TO</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>999463.0</td>\n",
       "      <td>231690.0</td>\n",
       "      <td>40.802607</td>\n",
       "      <td>-73.945052</td>\n",
       "      <td>(40.802606608, -73.945051911)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>968417082</td>\n",
       "      <td>12/31/2015</td>\n",
       "      <td>23:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/31/2015</td>\n",
       "      <td>344</td>\n",
       "      <td>ASSAULT 3 &amp; RELATED OFFENSES</td>\n",
       "      <td>101.0</td>\n",
       "      <td>ASSAULT 3</td>\n",
       "      <td>...</td>\n",
       "      <td>105.0</td>\n",
       "      <td>INSIDE</td>\n",
       "      <td>RESIDENCE-HOUSE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1060183.0</td>\n",
       "      <td>177862.0</td>\n",
       "      <td>40.654549</td>\n",
       "      <td>-73.726339</td>\n",
       "      <td>(40.654549444, -73.726338791)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CMPLNT_NUM CMPLNT_FR_DT CMPLNT_FR_TM CMPLNT_TO_DT CMPLNT_TO_TM      RPT_DT  \\\n",
       "0   101109527   12/31/2015     23:45:00          NaN          NaN  12/31/2015   \n",
       "1   153401121   12/31/2015     23:36:00          NaN          NaN  12/31/2015   \n",
       "2   569369778   12/31/2015     23:30:00          NaN          NaN  12/31/2015   \n",
       "3   968417082   12/31/2015     23:30:00          NaN          NaN  12/31/2015   \n",
       "\n",
       "   KY_CD                        OFNS_DESC  PD_CD  \\\n",
       "0    113                          FORGERY  729.0   \n",
       "1    101  MURDER & NON-NEGL. MANSLAUGHTER    NaN   \n",
       "2    117                  DANGEROUS DRUGS  503.0   \n",
       "3    344     ASSAULT 3 & RELATED OFFENSES  101.0   \n",
       "\n",
       "                          PD_DESC  ... ADDR_PCT_CD LOC_OF_OCCUR_DESC  \\\n",
       "0  FORGERY,ETC.,UNCLASSIFIED-FELO  ...        44.0            INSIDE   \n",
       "1                             NaN  ...       103.0           OUTSIDE   \n",
       "2  CONTROLLED SUBSTANCE,INTENT TO  ...        28.0               NaN   \n",
       "3                       ASSAULT 3  ...       105.0            INSIDE   \n",
       "\n",
       "     PREM_TYP_DESC PARKS_NM  HADEVELOPT X_COORD_CD Y_COORD_CD   Latitude  \\\n",
       "0   BAR/NIGHT CLUB      NaN         NaN  1007314.0   241257.0  40.828848   \n",
       "1              NaN      NaN         NaN  1043991.0   193406.0  40.697338   \n",
       "2            OTHER      NaN         NaN   999463.0   231690.0  40.802607   \n",
       "3  RESIDENCE-HOUSE      NaN         NaN  1060183.0   177862.0  40.654549   \n",
       "\n",
       "   Longitude                        Lat_Lon  \n",
       "0 -73.916661  (40.828848333, -73.916661142)  \n",
       "1 -73.784557  (40.697338138, -73.784556739)  \n",
       "2 -73.945052  (40.802606608, -73.945051911)  \n",
       "3 -73.726339  (40.654549444, -73.726338791)  \n",
       "\n",
       "[4 rows x 24 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "1Hv_etH6hLTr"
   },
   "outputs": [],
   "source": [
    "#residencecount, othercount, financecount, foodbevcount, tranportcount, retialcount, worshipcount, healthcount, pubcount = makeCategories(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "7Fk6cp3Q4Wak"
   },
   "outputs": [],
   "source": [
    "# #Assign zipcodes to each row\n",
    "\n",
    "# import geopy\n",
    "# from geopy.point import Point\n",
    "\n",
    "# def get_zipcode(df5, geolocator, Latitude, Longitude):\n",
    "#   zipcode = 99999\n",
    "#   try: \n",
    "#     # location = geolocator.reverse(Point(df1[\"Latitude\"], df1[\"Longitude\"]))\n",
    "#     location = geolocator.reverse(Point(df5[\"Latitude\"], df5[\"Longitude\"]))\n",
    "#     zipcode = location.raw['address']['postcode']\n",
    "#     zipcode = int(zipcode)\n",
    "#   except:\n",
    "#     pass\n",
    "#   return zipcode\n",
    "\n",
    "# geolocator = geopy.Nominatim(user_agent='AI-application')\n",
    "# df1['Zipcodes'] = df1.apply(get_zipcode, axis=1, geolocator=geolocator, Latitude=df1[\"Latitude\"], Longitude=df1[\"Longitude\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "Lh83y84zCasN"
   },
   "outputs": [],
   "source": [
    "# from multiprocessing import Process\n",
    "# p1 = Process(target=get_zipcode, args=(df5,))\n",
    "# df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yiRyutJAcGrs"
   },
   "source": [
    "HYPOTHESIS: Segregate Burrows based on type of crime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "pM78VVk-91ap",
    "outputId": "39155b90-bb9c-4af4-e1af-73577170e5fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BORO_NM</th>\n",
       "      <th>2010</th>\n",
       "      <th>2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NYC TOTAL</td>\n",
       "      <td>8,242,624</td>\n",
       "      <td>8,550,971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRONX</td>\n",
       "      <td>1,385,108</td>\n",
       "      <td>1,446,788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>2,552,911</td>\n",
       "      <td>2,648,452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>1,585,873</td>\n",
       "      <td>1,638,281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QUEENS</td>\n",
       "      <td>2,250,002</td>\n",
       "      <td>2,330,295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>468,730</td>\n",
       "      <td>487,155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            BORO_NM       2010       2020\n",
       "0         NYC TOTAL  8,242,624  8,550,971\n",
       "1             BRONX  1,385,108  1,446,788\n",
       "2          BROOKLYN  2,552,911  2,648,452\n",
       "3         MANHATTAN  1,585,873  1,638,281\n",
       "4            QUEENS  2,250,002  2,330,295\n",
       "5     STATEN ISLAND    468,730    487,155"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pop Size\n",
    "feature_1 = df3[['Borough','2010','2020']]\n",
    "feature_1 = feature_1.apply(lambda x: x.str.upper() if x.dtype == \"object\" else x)  \n",
    "feature_1.rename(columns = {'Borough':'BORO_NM'}, inplace = True)\n",
    "feature_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I00uct8snoa0",
    "outputId": "d734a885-8595-4a11-be8c-0b2996ea57dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [CMPLNT_FR_DT, CMPLNT_TO_DT, CMPLNT_TO_TM, OFNS_DESC, PD_CD, PD_DESC, CRM_ATPT_CPTD_CD, ADDR_PCT_CD, LOC_OF_OCCUR_DESC, PREM_TYP_DESC, PARKS_NM, HADEVELOPT, X_COORD_CD, Y_COORD_CD, Latitude, Longitude, Lat_Lon]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#df1 = df1.dropna()\n",
    "#df1.head(100)\n",
    "null_columns=df1.columns[df1.isnull().any()]\n",
    "df1[null_columns].isnull().sum()\n",
    "df1.drop(329156, inplace=True)\n",
    "print(df1[df1['ADDR_PCT_CD'].isnull()][null_columns].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OIPfgbYa9vwS",
    "outputId": "ba233716-8bbd-45cf-a8bd-dd387a5eb57d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 44., 103.,  28., 105.,  13.,  71.,   7.,  46.,  48.,  19.,  41.,\n",
       "        14.,  67.,  17.,  61., 102., 110., 108.,  75.,  73.,  60.,  68.,\n",
       "        79., 121.,  23.,  42., 115.,  52., 122.,   1.,  72., 109.,  24.,\n",
       "        81.,  90., 112.,  43.,  84.,  47.,  77., 101.,  83., 113., 120.,\n",
       "        70.,  69.,  66., 114.,  76.,  63.,  45., 106.,  10.,  78.,   6.,\n",
       "         5.,  94.,  40.,  34.,  32.,  50.,  25., 100.,  18.,  20., 111.,\n",
       "       107.,  30.,  49.,  88.,  26., 123.,   9., 104.,  33.,  62.,  22.])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['ADDR_PCT_CD'].unique()\n",
    "# df1['ADDR_PCT_CD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "QbWbc0j889T7"
   },
   "outputs": [],
   "source": [
    "# Time of Day\n",
    "feature_set = df1[['CMPLNT_FR_TM','BORO_NM','ADDR_PCT_CD']]\n",
    "feature_set.set_index('ADDR_PCT_CD', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "VW9JYzwk0TFm"
   },
   "outputs": [],
   "source": [
    "bronx_ = 1385108\n",
    "brook_ = 2552911\n",
    "manha_ = 1585873\n",
    "queen_ = 2250002\n",
    "state_ = 468730"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29IUAZqFEMuO",
    "outputId": "fb034014-c981-4579-d3fb-be4c0000a0ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hnade\\AppData\\Local\\Temp/ipykernel_4352/2546497666.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_set['Count'] = df1.groupby(by='ADDR_PCT_CD')['CMPLNT_NUM'].count()\n",
      "C:\\Users\\hnade\\AppData\\Local\\Temp/ipykernel_4352/2546497666.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_set['Pop'] = 0\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "feature_set['Count'] = df1.groupby(by='ADDR_PCT_CD')['CMPLNT_NUM'].count()\n",
    "feature_set['Pop'] = 0\n",
    "feature_set.loc[feature_set[\"BORO_NM\"] == \"MANHATTAN\", \"Pop\"] = manha_\n",
    "feature_set.loc[feature_set[\"BORO_NM\"] == \"BRONX\", \"Pop\"] = bronx_\n",
    "feature_set.loc[feature_set[\"BORO_NM\"] == \"QUEENS\", \"Pop\"] = queen_\n",
    "feature_set.loc[feature_set[\"BORO_NM\"] == \"STATEN ISLAND\", \"Pop\"] = state_\n",
    "feature_set.loc[feature_set[\"BORO_NM\"] == \"BROOKLYN\", \"Pop\"] = brook_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "TuC9lNCXrEoX"
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------#\n",
    "# Start Part 2 of the Prject using Keras/scikitlearn\n",
    "\n",
    "# sklearn imports below\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31Fh5k2jItXK",
    "outputId": "a8085b58-fc21-44a4-8ce7-fe1f0e0f846f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum crime count =>  832\n",
      "max crime count =>  36460\n",
      "mean crime count =>  15972.79769858875\n"
     ]
    }
   ],
   "source": [
    "print(\"minimum crime count => \", feature_set['Count'].min())\n",
    "print(\"max crime count => \", feature_set['Count'].max())\n",
    "print(\"mean crime count => \", feature_set['Count'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "id": "SwBoRoZm5dB4",
    "outputId": "93465386-7bc6-4129-e982-8e68303d5a27"
   },
   "outputs": [],
   "source": [
    "# Add Class Low Medium, High\n",
    "# if time between 6pm and 4am, and count > 10, then high_crime 26217\n",
    "# if time between 6pm and 4am, and count < 10 but > 5, then medium_crime 7570\n",
    "# if time between 6pm and 4am, and count < 5, then low_crime\n",
    "#\n",
    "#feature_set['Class'] = 0\n",
    "\n",
    "# Change Count everytime you change Sample Size\n",
    "feature_set.loc[feature_set[\"Count\"] >= 26217, \"Class\"]          = 'high'\n",
    "feature_set.loc[feature_set[\"Count\"] <= 7570, \"Class\"]           = 'med'\n",
    "feature_set.loc[feature_set[\"Count\"].between(7571,26216,inclusive=\"both\"), \"Class\"] = 'med'\n",
    "\n",
    " \n",
    "# Split time into hh mm ss\n",
    "feature_set[['hour', 'minutes', 'seconds']] = feature_set['CMPLNT_FR_TM'].str.split(':', expand=True)\n",
    "feature_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0euV_6fbdyc"
   },
   "outputs": [],
   "source": [
    "# Drop the Boro Name for now\n",
    "#feature_set.drop(['BORO_NM'], axis=1, inplace=True)\n",
    "\n",
    "# Can we add tags to each data based on location of crime ( Health, residence, Retail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynJLYAcvsEyE"
   },
   "outputs": [],
   "source": [
    "# Creating the Main Function/ Calling these Algorithms\n",
    "X = feature_set[['Pop','hour','Count']]\n",
    "y = feature_set[['Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHcaTkIRrZIk"
   },
   "outputs": [],
   "source": [
    "# Function to Create \n",
    "def mlSVM(X,y,p): # Ajinkya\n",
    "  svm_prediction = 0\n",
    "  #svcObj = LinearSVC()\n",
    "  svcObj = SVC()\n",
    "  start = time.time()\n",
    "  svcObj.fit(X,y)\n",
    "  stop = time.time()\n",
    "  svm_prediction = svcObj.predict(p)\n",
    "  print(f\"Training time: {stop - start}s\")\n",
    "    \n",
    "  return svm_prediction\n",
    "\n",
    "def mlRegression(X, y, p): # Nency\n",
    "  # init y_predict\n",
    "  linear_prediction = 0\n",
    "  \n",
    "  regObj = LogisticRegression()\n",
    "  start = time.time()\n",
    "  regObj.fit(X, y)\n",
    "  stop = time.time()\n",
    "  logistic_prediction = regObj.predict(p)\n",
    "  logistic_prediction_score = regObj.score(X,y)\n",
    "  print(f\"Training time: {stop - start}s\")\n",
    "  return logistic_prediction,logistic_prediction_score\n",
    "\n",
    "def mlRandomForest(X, y, p): # Hamza\n",
    "  # init y_predict\n",
    "  rf_prediction = 0\n",
    "\n",
    "  rfObj = RandomForestClassifier()\n",
    "  start = time.time()\n",
    "  rfObj.fit(X, y)\n",
    "  stop = time.time()\n",
    "  rf_prediction = rfObj.predict(p)\n",
    "  print(f\"Training time: {stop - start}s\")\n",
    "  return rf_prediction\n",
    "\n",
    "def mlBayes(X, y, p): # Monica\n",
    "  # init y_predict\n",
    "  bayes_prediction = 0\n",
    "\n",
    "  bayesObj = GaussianNB()   # create an instance of the object\n",
    "  start = time.time()\n",
    "  bayesObj.fit(X,y)        # fit or train the model\n",
    "  stop = time.time()\n",
    "  bayes_prediction = bayesObj.predict(p)\n",
    "  print(f\"Training time: {stop - start}s\")\n",
    "  return bayes_prediction\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "L7SrtjHOM1YW",
    "outputId": "ba9919f3-ebd3-49b4-85a2-7672449565e9"
   },
   "outputs": [],
   "source": [
    "feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jkXWzap0FjWA",
    "outputId": "e9db74bd-1b9a-434f-d586-dcbec61f0cef"
   },
   "outputs": [],
   "source": [
    "feature_set.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hfwYE7kE_cwV",
    "outputId": "9860a2d3-651d-4207-e951-0543f4c097d4"
   },
   "outputs": [],
   "source": [
    "X_train , X_test , y_train, y_test = train_test_split(X, y, test_size=0.3,random_state= 42)\n",
    "X_train= X_train.astype(int)\n",
    "X_test = X_test.astype(int)\n",
    "\n",
    "# y_train = y_train.astype(int)\n",
    "# y_test = y_test.astype(int)\n",
    "\n",
    "\n",
    "\n",
    "y_reg,score_regression = mlRegression(X_train, y_train, X_test)\n",
    "score_regression = accuracy_score(y_test,y_reg)\n",
    "\n",
    "y_rf  = mlRandomForest(X_train, y_train, X_test)\n",
    "score_randomForest = accuracy_score(y_test,y_rf)\n",
    "\n",
    "y_bayes = mlBayes(X_train, y_train, X_test)\n",
    "score_bayes = accuracy_score(y_test,y_bayes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('The accuracy score is bayes = ', score_bayes)\n",
    "\n",
    "print('The accuracy score is reg   = ', score_regression)\n",
    "print('The accuracy score is rfores= ', score_randomForest)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYt3U6nJLs9E"
   },
   "source": [
    "Plot predicted values  <br> y= test x= Zipcode <br> Heat Map If Possible otherwise any chart that can help us visualize the predicted values<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zqn6DtD7CGx0",
    "outputId": "b8ad36a9-1487-405f-a049-c2c86a1accc1"
   },
   "outputs": [],
   "source": [
    "y_svm = mlSVM(X_train, y_train, X_test)\n",
    "score_SVM = accuracy_score(y_test,y_svm)\n",
    "print('The accuracy score is svm   = ', score_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "svXAhxtbOcdD"
   },
   "outputs": [],
   "source": [
    "# Crime Count per precinct\n",
    "# min = 832\n",
    "# mean = 15973\n",
    "# max = 36460\n",
    "\n",
    "# How did we calculate our Class range for low med high \n",
    "# crime rate\n",
    "# First Trial\n",
    "# For Crime Rate Class Low: (mean - min)/2 : (15973 - 832)/2 = 7570\n",
    "# For Crime Rate Class High: (max - mean): 36460 - 15973 : 26217\n",
    "# For Crime Rate Class Med: everything in between  7571 - 26216\n",
    "# Accuracy Score:\n",
    "#                 bayes:0.9991512290489474\n",
    "#                 svm:\n",
    "#                 reg: 0.9254750494719023\n",
    "#                 rfores: 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfgraph = pd.DataFrame({'Algorithms':['Bayes', 'Regression', 'Random Forest', 'SVM'], \"Accuracy\":[score_bayes, score_regression,score_randomForest, score_SVM]})\n",
    "ax = dfgraph.plot.bar(x='Algorithms', y='Accuracy', rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.datasets import make_blobs\n",
    "X, y = make_blobs(330, 3, centers=3, random_state=42, cluster_std=1.5)\n",
    "\n",
    "np.save('./datasv.npy', (X_train, X_test, y_train, y_test))\n",
    "X_train, X_test, y_train, y_test = np.load('./datasv.npy', allow_pickle=True)\n",
    "\n",
    "plt.scatter(y_test, y_test, c=y, s=50, cmap='RdBu');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "inputs,targets=make_blobs(n_samples=100, centers=2, random_state=0, cluster_std=0.7)\n",
    "plt.scatter(X_train[:,0],y_test[:,1],c=targets, cmap='winter')\n",
    "plt.title('Data points of the 2 classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# Configuration options\n",
    "blobs_random_seed = 42\n",
    "centers = [(0,0), (5,5)]\n",
    "cluster_std = 1.5\n",
    "frac_test_split = 0.33\n",
    "num_features_for_samples = 2\n",
    "num_samples_total = 1000\n",
    "\n",
    "# Generate data\n",
    "inputs, targets = make_blobs(n_samples = num_samples_total, centers = centers, n_features = num_features_for_samples, cluster_std = cluster_std)\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, targets, test_size=frac_test_split, random_state=blobs_random_seed)\n",
    "\n",
    "# Save and load temporarily\n",
    "np.save('./datasv.npy', (X_train, X_test, y_train, y_test))\n",
    "X_train, X_test, y_train, y_test = np.load('./datasv.npy', allow_pickle=True)\n",
    "\n",
    "# Generate scatter plot for training data \n",
    "plt.scatter(X_train[:,0], X_train[:,1])\n",
    "plt.title('Linearly separable data')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.show()\n",
    "\n",
    "# Initialize SVM classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "# Fit data\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_train.iloc[:0,:1],y_train.iloc[:0,:1])\n",
    "plt.scatter(y_test.iloc[:,0], y_test.iloc[:,1], color='red')\n",
    "plt.title('Linearly separable data with support vectors')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRG2K1ZUJIbh"
   },
   "outputs": [],
   "source": [
    "#Plot SVM\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "\n",
    "\n",
    "def make_meshgrid(x, y, h=.02):\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out\n",
    "\n",
    "model = svm.SVC(kernel='linear')\n",
    "clf = model.fit(X, y)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# title for the plots\n",
    "title = ('Decision surface of linear SVC ')\n",
    "# Set-up grid for plotting.\n",
    "X0, X1 = X[:, 0], X[:, 1]\n",
    "xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "\n",
    "\n",
    "ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
    "ax.set_ylabel('y label here')\n",
    "ax.set_xlabel('x label here')\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "ax.set_title(title)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ProjectArtificalIntelligenceFinal_05_13_22.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
